{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj4loBHHeq_q",
        "outputId": "2aff6ee6-c51d-462e-8bcb-2644018a1478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (0.90)\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-1.7.3-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.21.6)\n",
            "Installing collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.7.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost) (8.1.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade xgboost\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMgANKBGnlZo",
        "outputId": "7c3bd03d-a14c-49af-d848-c1c494619e73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('2.9.2', '1.21.6', '1.3.5', '1.7.3', '1.1.1', '1.0.2')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pandas\n",
        "import pandas as pd\n",
        "\n",
        "import xgboost as xgb\n",
        "import catboost as cab\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "tf.__version__, np.__version__, pd.__version__, xgb.__version__, cab.__version__, sklearn.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz1d59FzAfE-",
        "outputId": "dbcbf1c2-53e6-4f25-9fa9-cd29536da971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWph_eMKnufL",
        "outputId": "d2b8490d-a29d-4a8d-e25e-7d9f116ad0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/tabular_playground\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd drive/MyDrive/tabular_playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "-Dtx3u_jpIMi",
        "outputId": "a418841d-c002-4c17-ccd3-2bad13eb14c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c10de7ec-6c1f-4eeb-9344-6b7f800487c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_code</th>\n",
              "      <th>loading</th>\n",
              "      <th>attribute_0</th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>measurement_0</th>\n",
              "      <th>measurement_1</th>\n",
              "      <th>measurement_2</th>\n",
              "      <th>...</th>\n",
              "      <th>measurement_9</th>\n",
              "      <th>measurement_10</th>\n",
              "      <th>measurement_11</th>\n",
              "      <th>measurement_12</th>\n",
              "      <th>measurement_13</th>\n",
              "      <th>measurement_14</th>\n",
              "      <th>measurement_15</th>\n",
              "      <th>measurement_16</th>\n",
              "      <th>measurement_17</th>\n",
              "      <th>failure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>80.10</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>10.672</td>\n",
              "      <td>15.859</td>\n",
              "      <td>17.594</td>\n",
              "      <td>15.193</td>\n",
              "      <td>15.029</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.034</td>\n",
              "      <td>14.684</td>\n",
              "      <td>764.100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>84.89</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>12.448</td>\n",
              "      <td>17.947</td>\n",
              "      <td>17.915</td>\n",
              "      <td>11.755</td>\n",
              "      <td>14.732</td>\n",
              "      <td>15.425</td>\n",
              "      <td>14.395</td>\n",
              "      <td>15.631</td>\n",
              "      <td>682.057</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>82.43</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>12.715</td>\n",
              "      <td>15.607</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.798</td>\n",
              "      <td>16.711</td>\n",
              "      <td>18.631</td>\n",
              "      <td>14.094</td>\n",
              "      <td>17.946</td>\n",
              "      <td>663.376</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A</td>\n",
              "      <td>101.07</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>12.471</td>\n",
              "      <td>16.346</td>\n",
              "      <td>18.377</td>\n",
              "      <td>10.020</td>\n",
              "      <td>15.250</td>\n",
              "      <td>15.562</td>\n",
              "      <td>16.154</td>\n",
              "      <td>17.172</td>\n",
              "      <td>826.282</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>A</td>\n",
              "      <td>188.06</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>10.337</td>\n",
              "      <td>17.082</td>\n",
              "      <td>19.932</td>\n",
              "      <td>12.428</td>\n",
              "      <td>16.182</td>\n",
              "      <td>12.760</td>\n",
              "      <td>13.153</td>\n",
              "      <td>16.412</td>\n",
              "      <td>579.885</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26565</th>\n",
              "      <td>26565</td>\n",
              "      <td>E</td>\n",
              "      <td>158.95</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.177</td>\n",
              "      <td>17.942</td>\n",
              "      <td>10.112</td>\n",
              "      <td>15.795</td>\n",
              "      <td>18.572</td>\n",
              "      <td>16.144</td>\n",
              "      <td>NaN</td>\n",
              "      <td>729.131</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26566</th>\n",
              "      <td>26566</td>\n",
              "      <td>E</td>\n",
              "      <td>146.02</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>11.242</td>\n",
              "      <td>14.179</td>\n",
              "      <td>20.564</td>\n",
              "      <td>10.234</td>\n",
              "      <td>14.450</td>\n",
              "      <td>14.322</td>\n",
              "      <td>13.146</td>\n",
              "      <td>16.471</td>\n",
              "      <td>853.924</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26567</th>\n",
              "      <td>26567</td>\n",
              "      <td>E</td>\n",
              "      <td>115.62</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>11.407</td>\n",
              "      <td>16.437</td>\n",
              "      <td>17.476</td>\n",
              "      <td>8.668</td>\n",
              "      <td>15.069</td>\n",
              "      <td>16.599</td>\n",
              "      <td>15.590</td>\n",
              "      <td>14.065</td>\n",
              "      <td>750.364</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26568</th>\n",
              "      <td>26568</td>\n",
              "      <td>E</td>\n",
              "      <td>106.38</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>11.392</td>\n",
              "      <td>17.064</td>\n",
              "      <td>17.814</td>\n",
              "      <td>14.928</td>\n",
              "      <td>16.273</td>\n",
              "      <td>15.485</td>\n",
              "      <td>13.624</td>\n",
              "      <td>12.865</td>\n",
              "      <td>730.156</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26569</th>\n",
              "      <td>26569</td>\n",
              "      <td>E</td>\n",
              "      <td>131.20</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>10.611</td>\n",
              "      <td>15.603</td>\n",
              "      <td>19.703</td>\n",
              "      <td>11.006</td>\n",
              "      <td>15.875</td>\n",
              "      <td>13.366</td>\n",
              "      <td>16.527</td>\n",
              "      <td>17.890</td>\n",
              "      <td>602.354</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26570 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c10de7ec-6c1f-4eeb-9344-6b7f800487c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c10de7ec-6c1f-4eeb-9344-6b7f800487c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c10de7ec-6c1f-4eeb-9344-6b7f800487c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          id product_code  loading attribute_0 attribute_1  attribute_2  \\\n",
              "0          0            A    80.10  material_7  material_8            9   \n",
              "1          1            A    84.89  material_7  material_8            9   \n",
              "2          2            A    82.43  material_7  material_8            9   \n",
              "3          3            A   101.07  material_7  material_8            9   \n",
              "4          4            A   188.06  material_7  material_8            9   \n",
              "...      ...          ...      ...         ...         ...          ...   \n",
              "26565  26565            E   158.95  material_7  material_6            6   \n",
              "26566  26566            E   146.02  material_7  material_6            6   \n",
              "26567  26567            E   115.62  material_7  material_6            6   \n",
              "26568  26568            E   106.38  material_7  material_6            6   \n",
              "26569  26569            E   131.20  material_7  material_6            6   \n",
              "\n",
              "       attribute_3  measurement_0  measurement_1  measurement_2  ...  \\\n",
              "0                5              7              8              4  ...   \n",
              "1                5             14              3              3  ...   \n",
              "2                5             12              1              5  ...   \n",
              "3                5             13              2              6  ...   \n",
              "4                5              9              2              8  ...   \n",
              "...            ...            ...            ...            ...  ...   \n",
              "26565            9              6             16              4  ...   \n",
              "26566            9             10             12              8  ...   \n",
              "26567            9              1             10              1  ...   \n",
              "26568            9              2              9              4  ...   \n",
              "26569            9              6             19              1  ...   \n",
              "\n",
              "       measurement_9  measurement_10  measurement_11  measurement_12  \\\n",
              "0             10.672          15.859          17.594          15.193   \n",
              "1             12.448          17.947          17.915          11.755   \n",
              "2             12.715          15.607             NaN          13.798   \n",
              "3             12.471          16.346          18.377          10.020   \n",
              "4             10.337          17.082          19.932          12.428   \n",
              "...              ...             ...             ...             ...   \n",
              "26565            NaN          12.177          17.942          10.112   \n",
              "26566         11.242          14.179          20.564          10.234   \n",
              "26567         11.407          16.437          17.476           8.668   \n",
              "26568         11.392          17.064          17.814          14.928   \n",
              "26569         10.611          15.603          19.703          11.006   \n",
              "\n",
              "       measurement_13  measurement_14  measurement_15  measurement_16  \\\n",
              "0              15.029             NaN          13.034          14.684   \n",
              "1              14.732          15.425          14.395          15.631   \n",
              "2              16.711          18.631          14.094          17.946   \n",
              "3              15.250          15.562          16.154          17.172   \n",
              "4              16.182          12.760          13.153          16.412   \n",
              "...               ...             ...             ...             ...   \n",
              "26565          15.795          18.572          16.144             NaN   \n",
              "26566          14.450          14.322          13.146          16.471   \n",
              "26567          15.069          16.599          15.590          14.065   \n",
              "26568          16.273          15.485          13.624          12.865   \n",
              "26569          15.875          13.366          16.527          17.890   \n",
              "\n",
              "       measurement_17  failure  \n",
              "0             764.100        0  \n",
              "1             682.057        0  \n",
              "2             663.376        0  \n",
              "3             826.282        0  \n",
              "4             579.885        0  \n",
              "...               ...      ...  \n",
              "26565         729.131        0  \n",
              "26566         853.924        0  \n",
              "26567         750.364        0  \n",
              "26568         730.156        0  \n",
              "26569         602.354        0  \n",
              "\n",
              "[26570 rows x 26 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv = pd.read_csv('train.csv') # get dataset\n",
        "csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XMZW9N_Iiaow"
      },
      "outputs": [],
      "source": [
        "columns = csv.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-X0Cdo8bcXEh"
      },
      "outputs": [],
      "source": [
        "attr_map = {'material_5' : 0, 'material_6' : 1, 'material_7' : 2, 'material_8' : 3,} # to map string to categorical number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Yi89VA71pO7O"
      },
      "outputs": [],
      "source": [
        "csv['attribute_0'] = csv['attribute_0'].map(attr_map)\n",
        "csv['attribute_1'] = csv['attribute_1'].map(attr_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_gfTbA_dVH8",
        "outputId": "b6fc95e2-51b3-4cff-d3d3-67e1988fbe0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127.82623252279637\n",
            "False\n",
            "17.79152751155065\n",
            "False\n",
            "11.731987861094039\n",
            "False\n",
            "17.1278036224608\n",
            "False\n",
            "17.510758787925816\n",
            "False\n",
            "11.71662411734873\n",
            "False\n",
            "19.024713893895463\n",
            "False\n",
            "11.430724539320522\n",
            "False\n",
            "16.117710565888405\n",
            "False\n",
            "19.17208545135846\n",
            "False\n",
            "11.702464455925348\n",
            "False\n",
            "15.652903573156959\n",
            "False\n",
            "16.048444120505344\n",
            "False\n",
            "14.995554293391963\n",
            "False\n",
            "16.460726941946035\n",
            "False\n",
            "701.2690585522523\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "for column in columns:\n",
        "  if csv[column].isnull().any():\n",
        "    # print(csv[column].mean)\n",
        "    temp = csv[column].to_numpy()\n",
        "    temp = temp[~np.isnan(temp)]\n",
        "    csv[column] = csv[column].fillna(np.mean(temp)) # fill nan\n",
        "    print(np.mean(temp))\n",
        "    print(csv[column].isnull().any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofZrZqJBpPc0",
        "outputId": "d857e4d0-d84c-4273-c0af-ed3fefb5dfbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((26570, 23), (26570,))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = csv.to_numpy()[:, 2:25] # using only the 3 - 25 columns\n",
        "Y = csv.to_numpy()[:, 25]\n",
        "X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ng4HvCN6yNl5"
      },
      "outputs": [],
      "source": [
        "# std = []\n",
        "# mean = []\n",
        "# for attr in range(5, X.shape[1]):\n",
        "#   std.append(np.std(X[:, attr]))\n",
        "#   mean.append(np.mean(X[:, attr]))\n",
        "#   X[:, attr] = (X[:, attr] - mean[-1]) / std[-1]\n",
        "  # print(std[-1], mean[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I6lVU7RMlEeb"
      },
      "outputs": [],
      "source": [
        "# x_pass = X[Y == 1]\n",
        "# y_pass = Y[Y == 1]\n",
        "# x_failure = X[Y == 0]\n",
        "# y_failure = Y[Y == 0]\n",
        "# x_pass.shape, x_failure.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CFjpGlgOpX4w"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.05, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2JQXcL9mZPp",
        "outputId": "740093ad-b100-4e48-f994-fba62f66c459"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5361, 23), (19880, 23), (19880,), (5361,))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_pass = x_train[y_train == 1]\n",
        "y_pass = y_train[y_train == 1]\n",
        "x_failure = x_train[y_train == 0]\n",
        "y_failure = y_train[y_train == 0]\n",
        "x_pass.shape, x_failure.shape, y_failure.shape, y_pass.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YLrhuy-3O_y",
        "outputId": "2190c7c3-ad9d-41fb-98c0-2f77263aea95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((73490, 23), (73490,))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# over sampling\n",
        "x_amp = x_failure.copy() # [:7000]\n",
        "y_amp = y_failure.copy() # [:7000]\n",
        "for i in range(10):\n",
        "    x_amp = np.concatenate([x_amp, x_pass], axis = 0)\n",
        "    y_amp = np.concatenate([y_amp, y_pass], axis = 0)\n",
        "x_amp.shape, y_amp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fq74v0Tpnkt"
      },
      "outputs": [],
      "source": [
        "# hyperparameters, not recommended to change\n",
        "# n_estimators = 104590\n",
        "# max_depth = 1\n",
        "# gamma = 0.42\n",
        "# colsample_bytree = 0.6\n",
        "# alpha = 1\n",
        "# booster = 'gbtree'\n",
        "# learning_rate = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6qiVyMWqtyc"
      },
      "outputs": [],
      "source": [
        "# model = XGBClassifier(n_estimators = n_estimators, max_depth = max_depth, learning_rate = learning_rate, booster = booster, gamma = gamma, colsample_bytree = colsample_bytree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqOP4ov_qRD8"
      },
      "outputs": [],
      "source": [
        "# model_cat = CatBoostClassifier(learning_rate = 0.01, max_depth = 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar2nVm9tfFHa",
        "outputId": "992ecf86-db61-4453-eda9-1ce94eb3370c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.42, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=104590, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R4KhpR3ftoa",
        "outputId": "381d7ada-72ca-4ad7-8a68-192d5e0cce77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.6877351392024078, 0.6595958580476525)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# accuracy_score(y_test, model.predict(x_test)), accuracy_score(y_failure, model.predict(x_failure)) # check xgboost performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-etDVw7NBiB4"
      },
      "outputs": [],
      "source": [
        "# model_cat.fit(x_train, y_train) #\n",
        "# accuracy_score(y_test, model_cat.predict(x_test)), accuracy_score(y_failure, model_cat.predict(x_failure)) # check catboost performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTV_ftUEmFL9",
        "outputId": "0094be27-32cb-488f-e0ae-a3a93ef6c5d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 1.0\n",
            "0.003750234389649353 0.9994474583082178\n",
            "0.08644290268141759 0.9718706047819972\n",
            "0.3678979936246015 0.7971167369901547\n",
            "0.6561035064691543 0.5369198312236287\n"
          ]
        }
      ],
      "source": [
        "# oversampling test\n",
        "# for repeat in range(5): \n",
        "#   x_amp = x_failure.copy()\n",
        "#   y_amp = y_failure.copy()\n",
        "#   for i in range(repeat):\n",
        "#     x_amp = np.concatenate([x_amp, x_pass], axis = 0)\n",
        "#     y_amp = np.concatenate([y_amp, y_pass], axis = 0)\n",
        "#   model = XGBClassifier(n_estimators = n_estimators, max_depth = max_depth, learning_rate = learning_rate, booster = booster, gamma = gamma, colsample_bytree = colsample_bytree) \n",
        "#   model.fit(x_amp, y_amp)\n",
        "#   print(accuracy_score(y_pass, model.predict(x_pass)), accuracy_score(y_failure, model.predict(x_failure)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "HqHYvBYVf3hg",
        "outputId": "d46cd953-f364-432f-82a8-16e65af9a127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7069384701701888 0.5909319392781743\n",
            "0.7069384701701888 0.5909319392781743\n",
            "0.7069384701701888 0.5909319392781743\n",
            "0.7069384701701888 0.5909319392781743\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4ddc5842ce0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_amp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_amp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_failure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                                                     dtrain.handle))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# for n in range(100): # testing gamma\n",
        "#   model = XGBClassifier(n_estimators = n_estimators, max_depth = max_depth, learning_rate = 1, booster = booster, gamma = n / 100, colsample_bytree = 0.6) \n",
        "#   model.fit(x_amp, y_amp)\n",
        "#   print(accuracy_score(y_pass, model.predict(x_pass)), accuracy_score(y_failure, model.predict(x_failure)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuT8o4xp47uR"
      },
      "outputs": [],
      "source": [
        "net = models.Sequential([ # neural network\n",
        "\n",
        "    layers.Dense(23, input_shape = (23,)),\n",
        "    # layers.BatchNormalization(),\n",
        "    layers.Dense(64, kernel_regularizer = regularizers.L1(1e-5)),\n",
        "    # layers.LeakyReLU(alpha = 0.01),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(128, kernel_regularizer = regularizers.L1(1e-5)),\n",
        "    layers.LeakyReLU(alpha = 0.01),\n",
        "    layers.Dense(256, kernel_regularizer = regularizers.L1(1e-5)),\n",
        "    layers.LeakyReLU(alpha = 0.01),\n",
        "    layers.Dropout(0.25),\n",
        "    # layers.Dense(256, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5)),\n",
        "    # layers.LeakyReLU(alpha = 0.01),\n",
        "    # layers.BatchNormalization(),\n",
        "    # layers.Dense(128, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5)),\n",
        "    # layers.LeakyReLU(alpha = 0.01),\n",
        "    # layers.Dropout(0.2),\n",
        "    # layers.Dense(256, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5)),\n",
        "    # layers.LeakyReLU(alpha = 0.01),\n",
        "    # layers.BatchNormalization(),\n",
        "    # layers.Dense(512, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5)),\n",
        "    # layers.LeakyReLU(alpha = 0.01),\n",
        "    # layers.Dropout(0.2),\n",
        "    layers.Dense(256, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5), activation = 'relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(128, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5), activation = 'relu'),\n",
        "    layers.Dense(256, kernel_regularizer = regularizers.L1(1e-5), activation = 'relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(128, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5), activation = 'relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(64, kernel_regularizer = regularizers.L1(1e-5), activation = 'relu'),\n",
        "    layers.Dense(32, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5), activation = 'relu'),\n",
        "    layers.Dense(1, activation = 'sigmoid'),\n",
        "    # layers.Dense(1, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_pupByWSLHL",
        "outputId": "5fe84a03-3cae-43ef-f350-2421cdf34502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_141 (Dense)           (None, 23)                552       \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 64)                1536      \n",
            "                                                                 \n",
            " batch_normalization_46 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 128)               8320      \n",
            "                                                                 \n",
            " leaky_re_lu_23 (LeakyReLU)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 256)               33024     \n",
            "                                                                 \n",
            " leaky_re_lu_24 (LeakyReLU)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization_47 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 256)               33024     \n",
            "                                                                 \n",
            " batch_normalization_48 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 220,713\n",
            "Trainable params: 219,561\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ij5GBKjvPPkL"
      },
      "outputs": [],
      "source": [
        "input = layers.Input(shape=(23,)) # residual neural network\n",
        "res = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(input)\n",
        "x1 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(input)\n",
        "x1 = layers.LeakyReLU(alpha = 0.01)(x1)\n",
        "x1 = layers.Dropout(0.25)(x1)\n",
        "x1 = layers.BatchNormalization()(x1)\n",
        "x1 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x1)\n",
        "x1 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x1)\n",
        "x1 = layers.LeakyReLU(alpha = 0.01)(x1)\n",
        "x1 = layers.Dropout(0.2)(x1)\n",
        "x1 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x1)\n",
        "x1 = layers.BatchNormalization()(x1)\n",
        "x1 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x1)\n",
        "x1 = layers.Dropout(0.2)(x1)\n",
        "x1 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x1)\n",
        "x1 = layers.Dense(64, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x1)\n",
        "x1 = layers.BatchNormalization()(x1)\n",
        "\n",
        "x2 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(input)\n",
        "x2 = layers.LeakyReLU(alpha = 0.01)(x2)\n",
        "x2 = layers.Dropout(0.25)(x2)\n",
        "x2 = layers.BatchNormalization()(x2)\n",
        "x2 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x2)\n",
        "x2 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x2)\n",
        "x2 = layers.LeakyReLU(alpha = 0.01)(x2)\n",
        "x2 = layers.Dropout(0.2)(x2)\n",
        "x2 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x2)\n",
        "x2 = layers.BatchNormalization()(x2)\n",
        "x2 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x2)\n",
        "x2 = layers.Dropout(0.2)(x2)\n",
        "x2 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x2)\n",
        "x2 = layers.Dense(64, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x2)\n",
        "x2 = layers.BatchNormalization()(x2)\n",
        "\n",
        "x3 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(input)\n",
        "x3 = layers.LeakyReLU(alpha = 0.01)(x3)\n",
        "x3 = layers.Dropout(0.25)(x3)\n",
        "x3 = layers.BatchNormalization()(x3)\n",
        "x3 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x3)\n",
        "x3 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x3)\n",
        "x3 = layers.LeakyReLU(alpha = 0.01)(x3)\n",
        "x3 = layers.Dropout(0.2)(x3)\n",
        "x3 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x3)\n",
        "x3 = layers.BatchNormalization()(x3)\n",
        "x3 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x3)\n",
        "x3 = layers.Dropout(0.2)(x3)\n",
        "x3 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x3)\n",
        "x3 = layers.Dense(64, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x3)\n",
        "x3 = layers.BatchNormalization()(x3)\n",
        "\n",
        "x4 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(input)\n",
        "x4 = layers.LeakyReLU(alpha = 0.01)(x4)\n",
        "x4 = layers.Dropout(0.25)(x4)\n",
        "x4 = layers.BatchNormalization()(x4)\n",
        "x4 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x4)\n",
        "x4 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x4)\n",
        "x4 = layers.LeakyReLU(alpha = 0.01)(x4)\n",
        "x4 = layers.Dropout(0.2)(x4)\n",
        "x4 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x4)\n",
        "x4 = layers.BatchNormalization()(x4)\n",
        "x4 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x4)\n",
        "x4 = layers.Dropout(0.2)(x4)\n",
        "x4 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x4)\n",
        "x4 = layers.Dense(64, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x4)\n",
        "x4 = layers.BatchNormalization()(x4)\n",
        "\n",
        "x5 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(input)\n",
        "x5 = layers.LeakyReLU(alpha = 0.01)(x5)\n",
        "x5 = layers.Dropout(0.25)(x5)\n",
        "x5 = layers.BatchNormalization()(x5)\n",
        "x5 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x5)\n",
        "x5 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x5)\n",
        "x5 = layers.LeakyReLU(alpha = 0.01)(x5)\n",
        "x5 = layers.Dropout(0.2)(x5)\n",
        "x5 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x5)\n",
        "x5 = layers.BatchNormalization()(x5)\n",
        "x5 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x5)\n",
        "x5 = layers.Dropout(0.2)(x5)\n",
        "x5 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x5)\n",
        "x5 = layers.Dense(64, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x5)\n",
        "x5 = layers.BatchNormalization()(x5)\n",
        "\n",
        "x6 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(input)\n",
        "x6 = layers.LeakyReLU(alpha = 0.01)(x6)\n",
        "x6 = layers.Dropout(0.25)(x6)\n",
        "x6 = layers.BatchNormalization()(x6)\n",
        "x6 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x6)\n",
        "x6 = layers.Dense(64, kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x6)\n",
        "x6 = layers.LeakyReLU(alpha = 0.01)(x6)\n",
        "x6 = layers.Dropout(0.2)(x6)\n",
        "x6 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x6)\n",
        "x6 = layers.BatchNormalization()(x6)\n",
        "x6 = layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(x6)\n",
        "x6 = layers.Dropout(0.2)(x6)\n",
        "x6 = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x6)\n",
        "x6 = layers.Dense(64, activation = 'relu', kernel_regularizer = regularizers.L1L2(1e-5, 1e-5))(x6)\n",
        "x6 = layers.BatchNormalization()(x6)\n",
        "\n",
        "# equivalent to `added = tf.keras.layers.add([x1, x2])`\n",
        "added = tf.keras.layers.Concatenate()([x1, x2, x3, x4, x5, x6])\n",
        "out = layers.Dense(64, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(added)\n",
        "out = layers.BatchNormalization()(out)\n",
        "out = layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.L1(1e-5))(out)\n",
        "out = layers.Dense(1, activation = 'sigmoid')(out)\n",
        "residual = tf.keras.models.Model(inputs = input, outputs = out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDvQPjhuwAgc",
        "outputId": "bd94859d-6a7e-4bfc-8442-6d5468c5ffc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 23)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_47 (Dense)               (None, 64)           1536        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_54 (Dense)               (None, 64)           1536        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_61 (Dense)               (None, 64)           1536        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_68 (Dense)               (None, 64)           1536        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_75 (Dense)               (None, 64)           1536        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_82 (Dense)               (None, 64)           1536        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 64)           0           ['dense_47[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_14 (LeakyReLU)     (None, 64)           0           ['dense_54[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_16 (LeakyReLU)     (None, 64)           0           ['dense_61[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)     (None, 64)           0           ['dense_68[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_20 (LeakyReLU)     (None, 64)           0           ['dense_75[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_22 (LeakyReLU)     (None, 64)           0           ['dense_82[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 64)           0           ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 64)           0           ['leaky_re_lu_14[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_24 (Dropout)           (None, 64)           0           ['leaky_re_lu_16[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_27 (Dropout)           (None, 64)           0           ['leaky_re_lu_18[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_30 (Dropout)           (None, 64)           0           ['leaky_re_lu_20[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_33 (Dropout)           (None, 64)           0           ['leaky_re_lu_22[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 64)          256         ['dropout_18[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 64)          256         ['dropout_21[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 64)          256         ['dropout_24[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 64)          256         ['dropout_27[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 64)          256         ['dropout_30[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 64)          256         ['dropout_33[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_48 (Dense)               (None, 32)           2080        ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " dense_55 (Dense)               (None, 32)           2080        ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " dense_62 (Dense)               (None, 32)           2080        ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " dense_69 (Dense)               (None, 32)           2080        ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " dense_76 (Dense)               (None, 32)           2080        ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " dense_83 (Dense)               (None, 32)           2080        ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " dense_49 (Dense)               (None, 64)           2112        ['dense_48[0][0]']               \n",
            "                                                                                                  \n",
            " dense_56 (Dense)               (None, 64)           2112        ['dense_55[0][0]']               \n",
            "                                                                                                  \n",
            " dense_63 (Dense)               (None, 64)           2112        ['dense_62[0][0]']               \n",
            "                                                                                                  \n",
            " dense_70 (Dense)               (None, 64)           2112        ['dense_69[0][0]']               \n",
            "                                                                                                  \n",
            " dense_77 (Dense)               (None, 64)           2112        ['dense_76[0][0]']               \n",
            "                                                                                                  \n",
            " dense_84 (Dense)               (None, 64)           2112        ['dense_83[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_13 (LeakyReLU)     (None, 64)           0           ['dense_49[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_15 (LeakyReLU)     (None, 64)           0           ['dense_56[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_17 (LeakyReLU)     (None, 64)           0           ['dense_63[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_19 (LeakyReLU)     (None, 64)           0           ['dense_70[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_21 (LeakyReLU)     (None, 64)           0           ['dense_77[0][0]']               \n",
            "                                                                                                  \n",
            " leaky_re_lu_23 (LeakyReLU)     (None, 64)           0           ['dense_84[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 64)           0           ['leaky_re_lu_13[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)           (None, 64)           0           ['leaky_re_lu_15[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_25 (Dropout)           (None, 64)           0           ['leaky_re_lu_17[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_28 (Dropout)           (None, 64)           0           ['leaky_re_lu_19[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_31 (Dropout)           (None, 64)           0           ['leaky_re_lu_21[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)           (None, 64)           0           ['leaky_re_lu_23[0][0]']         \n",
            "                                                                                                  \n",
            " dense_50 (Dense)               (None, 128)          8320        ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            " dense_57 (Dense)               (None, 128)          8320        ['dropout_22[0][0]']             \n",
            "                                                                                                  \n",
            " dense_64 (Dense)               (None, 128)          8320        ['dropout_25[0][0]']             \n",
            "                                                                                                  \n",
            " dense_71 (Dense)               (None, 128)          8320        ['dropout_28[0][0]']             \n",
            "                                                                                                  \n",
            " dense_78 (Dense)               (None, 128)          8320        ['dropout_31[0][0]']             \n",
            "                                                                                                  \n",
            " dense_85 (Dense)               (None, 128)          8320        ['dropout_34[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 128)         512         ['dense_50[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 128)         512         ['dense_57[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 128)         512         ['dense_64[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 128)         512         ['dense_71[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 128)         512         ['dense_78[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 128)         512         ['dense_85[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_51 (Dense)               (None, 128)          16512       ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " dense_58 (Dense)               (None, 128)          16512       ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " dense_65 (Dense)               (None, 128)          16512       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " dense_72 (Dense)               (None, 128)          16512       ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " dense_79 (Dense)               (None, 128)          16512       ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " dense_86 (Dense)               (None, 128)          16512       ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 128)          0           ['dense_51[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)           (None, 128)          0           ['dense_58[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_26 (Dropout)           (None, 128)          0           ['dense_65[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_29 (Dropout)           (None, 128)          0           ['dense_72[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_32 (Dropout)           (None, 128)          0           ['dense_79[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_35 (Dropout)           (None, 128)          0           ['dense_86[0][0]']               \n",
            "                                                                                                  \n",
            " dense_52 (Dense)               (None, 32)           4128        ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " dense_59 (Dense)               (None, 32)           4128        ['dropout_23[0][0]']             \n",
            "                                                                                                  \n",
            " dense_66 (Dense)               (None, 32)           4128        ['dropout_26[0][0]']             \n",
            "                                                                                                  \n",
            " dense_73 (Dense)               (None, 32)           4128        ['dropout_29[0][0]']             \n",
            "                                                                                                  \n",
            " dense_80 (Dense)               (None, 32)           4128        ['dropout_32[0][0]']             \n",
            "                                                                                                  \n",
            " dense_87 (Dense)               (None, 32)           4128        ['dropout_35[0][0]']             \n",
            "                                                                                                  \n",
            " dense_53 (Dense)               (None, 64)           2112        ['dense_52[0][0]']               \n",
            "                                                                                                  \n",
            " dense_60 (Dense)               (None, 64)           2112        ['dense_59[0][0]']               \n",
            "                                                                                                  \n",
            " dense_67 (Dense)               (None, 64)           2112        ['dense_66[0][0]']               \n",
            "                                                                                                  \n",
            " dense_74 (Dense)               (None, 64)           2112        ['dense_73[0][0]']               \n",
            "                                                                                                  \n",
            " dense_81 (Dense)               (None, 64)           2112        ['dense_80[0][0]']               \n",
            "                                                                                                  \n",
            " dense_88 (Dense)               (None, 64)           2112        ['dense_87[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 64)          256         ['dense_53[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 64)          256         ['dense_60[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 64)          256         ['dense_67[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 64)          256         ['dense_74[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 64)          256         ['dense_81[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 64)          256         ['dense_88[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 384)          0           ['batch_normalization_21[0][0]', \n",
            "                                                                  'batch_normalization_24[0][0]', \n",
            "                                                                  'batch_normalization_27[0][0]', \n",
            "                                                                  'batch_normalization_30[0][0]', \n",
            "                                                                  'batch_normalization_33[0][0]', \n",
            "                                                                  'batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " dense_89 (Dense)               (None, 64)           24640       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 64)          256         ['dense_89[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_90 (Dense)               (None, 32)           2080        ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " dense_91 (Dense)               (None, 1)            33          ['dense_90[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 253,953\n",
            "Trainable params: 250,753\n",
            "Non-trainable params: 3,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "residual.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wUxJePJowDfU"
      },
      "outputs": [],
      "source": [
        "epochs = 32\n",
        "batch_size = 32\n",
        "lr = 4e-4\n",
        "ema_momentum = 0.9999\n",
        "use_ema = True\n",
        "weight_decay = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMZfDkDjwH95"
      },
      "outputs": [],
      "source": [
        "# net.compile(optimizer = keras.optimizers.experimental.AdamW(learning_rate = lr, weight_decay = weight_decay, ema_momentum = ema_momentum, use_ema = use_ema), loss = keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n",
        "net.compile(optimizer = keras.optimizers.Adam(learning_rate = lr), loss = keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5li650nnSWu2"
      },
      "outputs": [],
      "source": [
        "residual.compile(optimizer = keras.optimizers.Adam(lr), loss = keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2qRDZUOPwopx"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.05, shuffle = True)\n",
        "x_train = np.asarray(x_train).astype('float32')\n",
        "x_test = np.asarray(x_test).astype('float32')\n",
        "y_train = np.asarray(y_train).astype('int32')\n",
        "y_test = np.asarray(y_test).astype('int32')\n",
        "x_amp = np.asarray(x_amp).astype('float32')\n",
        "y_amp = np.asarray(y_amp).astype('int32')\n",
        "x_pass = np.asarray(x_pass).astype('float32')\n",
        "y_pass = np.asarray(y_pass).astype('int32')\n",
        "x_failure = np.asarray(x_failure).astype('float32')\n",
        "y_failure = np.asarray(y_failure).astype('int32')\n",
        "X = np.asarray(X).astype('float32')\n",
        "Y = np.asarray(Y).astype('int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YNE7fyY5poBS"
      },
      "outputs": [],
      "source": [
        "class_weight = {0 : (1 / len(x_failure)) * (len(x_train) / 2), 1 : (2.5 / len(x_pass)) * (len(x_train) / 2)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPGGx5JBwZG4",
        "outputId": "92ca03c8-327c-4782-af81-42e2f7cb8351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "789/789 [==============================] - 7s 7ms/step - loss: 1.2083 - accuracy: 0.2203 - val_loss: 1.0001 - val_accuracy: 0.2190\n",
            "Epoch 2/32\n",
            "789/789 [==============================] - 7s 9ms/step - loss: 1.1887 - accuracy: 0.2154 - val_loss: 1.1525 - val_accuracy: 0.2190\n",
            "Epoch 3/32\n",
            "789/789 [==============================] - 6s 7ms/step - loss: 1.1828 - accuracy: 0.2127 - val_loss: 1.0677 - val_accuracy: 0.2190\n",
            "Epoch 4/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1826 - accuracy: 0.2137 - val_loss: 1.0573 - val_accuracy: 0.2190\n",
            "Epoch 5/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1781 - accuracy: 0.2124 - val_loss: 1.0572 - val_accuracy: 0.2190\n",
            "Epoch 6/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1743 - accuracy: 0.2127 - val_loss: 1.1711 - val_accuracy: 0.2190\n",
            "Epoch 7/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1714 - accuracy: 0.2124 - val_loss: 1.1326 - val_accuracy: 0.2190\n",
            "Epoch 8/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1678 - accuracy: 0.2124 - val_loss: 1.0780 - val_accuracy: 0.2190\n",
            "Epoch 9/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1637 - accuracy: 0.2126 - val_loss: 1.1700 - val_accuracy: 0.2190\n",
            "Epoch 10/32\n",
            "789/789 [==============================] - 6s 7ms/step - loss: 1.1579 - accuracy: 0.2125 - val_loss: 1.0087 - val_accuracy: 0.2190\n",
            "Epoch 11/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1505 - accuracy: 0.2123 - val_loss: 1.1330 - val_accuracy: 0.2190\n",
            "Epoch 12/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1435 - accuracy: 0.2123 - val_loss: 1.1111 - val_accuracy: 0.2190\n",
            "Epoch 13/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1357 - accuracy: 0.2123 - val_loss: 1.0668 - val_accuracy: 0.2190\n",
            "Epoch 14/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1263 - accuracy: 0.2124 - val_loss: 1.1538 - val_accuracy: 0.2190\n",
            "Epoch 15/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1172 - accuracy: 0.2124 - val_loss: 1.0376 - val_accuracy: 0.2190\n",
            "Epoch 16/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.1073 - accuracy: 0.2123 - val_loss: 0.9987 - val_accuracy: 0.2190\n",
            "Epoch 17/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0983 - accuracy: 0.2123 - val_loss: 1.0955 - val_accuracy: 0.2190\n",
            "Epoch 18/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0873 - accuracy: 0.2127 - val_loss: 1.0683 - val_accuracy: 0.2190\n",
            "Epoch 19/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0812 - accuracy: 0.2123 - val_loss: 0.9457 - val_accuracy: 0.2190\n",
            "Epoch 20/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0728 - accuracy: 0.2123 - val_loss: 1.0644 - val_accuracy: 0.2190\n",
            "Epoch 21/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0660 - accuracy: 0.2126 - val_loss: 1.0439 - val_accuracy: 0.2190\n",
            "Epoch 22/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0617 - accuracy: 0.2136 - val_loss: 1.0032 - val_accuracy: 0.2190\n",
            "Epoch 23/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0549 - accuracy: 0.2123 - val_loss: 1.1036 - val_accuracy: 0.2190\n",
            "Epoch 24/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0543 - accuracy: 0.2124 - val_loss: 0.9397 - val_accuracy: 0.2190\n",
            "Epoch 25/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0514 - accuracy: 0.2140 - val_loss: 0.9735 - val_accuracy: 0.2190\n",
            "Epoch 26/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0479 - accuracy: 0.2138 - val_loss: 1.0620 - val_accuracy: 0.2190\n",
            "Epoch 27/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0465 - accuracy: 0.2147 - val_loss: 1.1080 - val_accuracy: 0.2190\n",
            "Epoch 28/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0424 - accuracy: 0.2151 - val_loss: 1.2440 - val_accuracy: 0.2190\n",
            "Epoch 29/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0431 - accuracy: 0.2123 - val_loss: 1.0344 - val_accuracy: 0.2190\n",
            "Epoch 30/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0415 - accuracy: 0.2125 - val_loss: 1.1255 - val_accuracy: 0.2190\n",
            "Epoch 31/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0416 - accuracy: 0.2125 - val_loss: 1.0554 - val_accuracy: 0.2190\n",
            "Epoch 32/32\n",
            "789/789 [==============================] - 5s 7ms/step - loss: 1.0393 - accuracy: 0.2123 - val_loss: 1.0826 - val_accuracy: 0.2190\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f27078b51c0>"
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = [x_test, y_test], class_weight = class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "186HrbcASZs3",
        "outputId": "023ec8ce-073d-42ae-f8e9-87791472248e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "789/789 [==============================] - 26s 21ms/step - loss: 1.3580 - accuracy: 0.2727 - val_loss: 1.4148 - val_accuracy: 0.2017\n",
            "Epoch 2/32\n",
            "789/789 [==============================] - 16s 20ms/step - loss: 1.2955 - accuracy: 0.2234 - val_loss: 1.2316 - val_accuracy: 0.2017\n",
            "Epoch 3/32\n",
            "789/789 [==============================] - 19s 24ms/step - loss: 1.2857 - accuracy: 0.2223 - val_loss: 1.2126 - val_accuracy: 0.2017\n",
            "Epoch 4/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2783 - accuracy: 0.2185 - val_loss: 1.1664 - val_accuracy: 0.2017\n",
            "Epoch 5/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2746 - accuracy: 0.2155 - val_loss: 1.3375 - val_accuracy: 0.2017\n",
            "Epoch 6/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2694 - accuracy: 0.2154 - val_loss: 1.2119 - val_accuracy: 0.2017\n",
            "Epoch 7/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2669 - accuracy: 0.2145 - val_loss: 1.2214 - val_accuracy: 0.2092\n",
            "Epoch 8/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2617 - accuracy: 0.2141 - val_loss: 1.2568 - val_accuracy: 0.2017\n",
            "Epoch 9/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2576 - accuracy: 0.2134 - val_loss: 1.1927 - val_accuracy: 0.2017\n",
            "Epoch 10/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2518 - accuracy: 0.2133 - val_loss: 1.0991 - val_accuracy: 0.2017\n",
            "Epoch 11/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2487 - accuracy: 0.2134 - val_loss: 1.2337 - val_accuracy: 0.2017\n",
            "Epoch 12/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2420 - accuracy: 0.2135 - val_loss: 1.1078 - val_accuracy: 0.2069\n",
            "Epoch 13/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2360 - accuracy: 0.2143 - val_loss: 1.1566 - val_accuracy: 0.2017\n",
            "Epoch 14/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2284 - accuracy: 0.2136 - val_loss: 1.1629 - val_accuracy: 0.2017\n",
            "Epoch 15/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2206 - accuracy: 0.2157 - val_loss: 1.1850 - val_accuracy: 0.2017\n",
            "Epoch 16/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2112 - accuracy: 0.2157 - val_loss: 1.1639 - val_accuracy: 0.2017\n",
            "Epoch 17/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.2036 - accuracy: 0.2148 - val_loss: 1.1277 - val_accuracy: 0.2017\n",
            "Epoch 18/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.1932 - accuracy: 0.2158 - val_loss: 1.1645 - val_accuracy: 0.2062\n",
            "Epoch 19/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.1822 - accuracy: 0.2171 - val_loss: 1.2421 - val_accuracy: 0.2017\n",
            "Epoch 20/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.1716 - accuracy: 0.2137 - val_loss: 1.1375 - val_accuracy: 0.2017\n",
            "Epoch 21/32\n",
            "789/789 [==============================] - 16s 20ms/step - loss: 1.1607 - accuracy: 0.2145 - val_loss: 1.0872 - val_accuracy: 0.2017\n",
            "Epoch 22/32\n",
            "789/789 [==============================] - 18s 23ms/step - loss: 1.1480 - accuracy: 0.2139 - val_loss: 1.0709 - val_accuracy: 0.2017\n",
            "Epoch 23/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.1384 - accuracy: 0.2142 - val_loss: 1.1067 - val_accuracy: 0.2062\n",
            "Epoch 24/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.1298 - accuracy: 0.2139 - val_loss: 1.0790 - val_accuracy: 0.2017\n",
            "Epoch 25/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.1208 - accuracy: 0.2132 - val_loss: 1.1158 - val_accuracy: 0.2017\n",
            "Epoch 26/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.1113 - accuracy: 0.2132 - val_loss: 1.0347 - val_accuracy: 0.2017\n",
            "Epoch 27/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.1032 - accuracy: 0.2134 - val_loss: 1.0783 - val_accuracy: 0.2017\n",
            "Epoch 28/32\n",
            "789/789 [==============================] - 15s 20ms/step - loss: 1.0991 - accuracy: 0.2132 - val_loss: 1.0850 - val_accuracy: 0.2017\n",
            "Epoch 29/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.0921 - accuracy: 0.2134 - val_loss: 1.0492 - val_accuracy: 0.2017\n",
            "Epoch 30/32\n",
            "789/789 [==============================] - 15s 19ms/step - loss: 1.0875 - accuracy: 0.2140 - val_loss: 1.0668 - val_accuracy: 0.2017\n",
            "Epoch 31/32\n",
            "789/789 [==============================] - 16s 20ms/step - loss: 1.0822 - accuracy: 0.2132 - val_loss: 1.0342 - val_accuracy: 0.2017\n",
            "Epoch 32/32\n",
            "789/789 [==============================] - 16s 20ms/step - loss: 1.0780 - accuracy: 0.2132 - val_loss: 1.0564 - val_accuracy: 0.2017\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae4b08e580>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "residual.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = [x_test, y_test], class_weight = class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a86NuomVjTw-"
      },
      "outputs": [],
      "source": [
        "# net.save('net')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "S7GfXLpfGEzj"
      },
      "outputs": [],
      "source": [
        "# residual.save('residual')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
